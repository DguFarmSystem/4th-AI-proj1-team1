# Evaluation Metrics êµ¬í˜„ íŒŒì¼ 

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
from typing import List, Tuple, Dict
import os
import matplotlib.font_manager as fm

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì•„ì„œ ì„¤ì • ì‹œë„
try:
    # ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°
    font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')
    korean_fonts = []
    
    for font_path in font_list:
        try:
            font_prop = fm.FontProperties(fname=font_path)
            font_name = font_prop.get_name()
            if any(keyword in font_name.lower() for keyword in ['nanum', 'malgun', 'batang', 'dotum', 'gulim']):
                korean_fonts.append(font_name)
        except:
            continue
    
    if korean_fonts:
        plt.rcParams['font.family'] = korean_fonts[0]
        print(f"í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {korean_fonts[0]}")
    else:
        print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        
except Exception as e:
    print(f"í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")

class RecommendationEvaluator:
    """
    ì¶”ì²œ ì‹œìŠ¤í…œ í‰ê°€ í´ë˜ìŠ¤ (ì •ë‹µ ë°ì´í„° ì—†ì´ë„ í‰ê°€ ê°€ëŠ¥)
    """
    def __init__(self, restaurants_df, feature_cols):
        self.restaurants_df = restaurants_df
        self.feature_cols = feature_cols
        self.evaluation_history = []
        
    def evaluate_recommendations(self, user_id, recommendations, user_interactions=None):
        """
        ì¶”ì²œ ê²°ê³¼ ì¢…í•© í‰ê°€
        """
        metrics = {}
        
        # 1. ë‹¤ì–‘ì„± í‰ê°€
        metrics['diversity'] = self.calculate_diversity(recommendations)
        
        # 2. ì»¤ë²„ë¦¬ì§€ í‰ê°€
        metrics['coverage'] = self.calculate_coverage(recommendations)
        
        # 3. ì‹ ê·œì„± í‰ê°€
        metrics['novelty'] = self.calculate_novelty(recommendations, user_interactions)
        
        # 4. ì¹´í…Œê³ ë¦¬ ë¶„í¬ í‰ê°€
        metrics['category_distribution'] = self.calculate_category_distribution(recommendations)
        
        # 5. í‰ê·  ì ìˆ˜
        metrics['avg_score'] = np.mean([score for _, score in recommendations])
        
        # í‰ê°€ ê¸°ë¡ ì €ì¥
        evaluation_record = {
            'user_id': user_id,
            'timestamp': pd.Timestamp.now(),
            'metrics': metrics,
            'recommendations': recommendations
        }
        self.evaluation_history.append(evaluation_record)
        
        return metrics
    
    def calculate_diversity(self, recommendations):
        """
        ì¶”ì²œ ê²°ê³¼ì˜ ë‹¤ì–‘ì„± ê³„ì‚° (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
        """
        if len(recommendations) == 0:
            return 0.0
            
        # ì¶”ì²œëœ ì•„ì´í…œë“¤ì˜ íŠ¹ì„± ë²¡í„° ê°€ì ¸ì˜¤ê¸°
        item_features = []
        for item_id, _ in recommendations:
            if item_id < len(self.restaurants_df):
                features = self.restaurants_df.iloc[item_id][self.feature_cols].values
                item_features.append(features)
        
        if len(item_features) < 2:
            return 0.0
        
        # ì•„ì´í…œ ê°„ í‰ê·  ê±°ë¦¬ ê³„ì‚° (ì½”ì‚¬ì¸ ê±°ë¦¬)
        distances = []
        for i in range(len(item_features)):
            for j in range(i+1, len(item_features)):
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                dot_product = np.dot(item_features[i], item_features[j])
                norm_i = np.linalg.norm(item_features[i])
                norm_j = np.linalg.norm(item_features[j])
                
                if norm_i > 0 and norm_j > 0:
                    cosine_sim = dot_product / (norm_i * norm_j)
                    cosine_distance = 1 - cosine_sim
                    distances.append(cosine_distance)
        
        return np.mean(distances) if distances else 0.0
    
    def calculate_coverage(self, recommendations):
        """
        ì»¤ë²„ë¦¬ì§€ ê³„ì‚° (ì „ì²´ ì•„ì´í…œ ì¤‘ ì¶”ì²œëœ ë¹„ìœ¨)
        """
        total_items = len(self.restaurants_df)
        recommended_items = set([item_id for item_id, _ in recommendations])
        return len(recommended_items) / total_items
    
    def calculate_novelty(self, recommendations, user_interactions=None):
        """
        ì‹ ê·œì„± ê³„ì‚° (ì¸ê¸°ë„ ê¸°ë°˜)
        """
        if user_interactions is None:
            # ì¸ê¸°ë„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëœë¤í•˜ê²Œ ìƒì„±
            popularity_scores = np.random.exponential(0.1, len(self.restaurants_df))
        else:
            # ì‹¤ì œ ìƒí˜¸ì‘ìš© ë°ì´í„°ë¡œ ì¸ê¸°ë„ ê³„ì‚°
            item_counts = Counter([interaction['item_id'] for interaction in user_interactions])
            popularity_scores = [item_counts.get(i, 0) for i in range(len(self.restaurants_df))]
        
        # ì¶”ì²œëœ ì•„ì´í…œë“¤ì˜ í‰ê·  ì‹ ê·œì„± (ì¸ê¸°ë„ ì—­ìˆ˜)
        novelty_scores = []
        for item_id, _ in recommendations:
            if item_id < len(popularity_scores):
                # ì¸ê¸°ë„ê°€ ë‚®ì„ìˆ˜ë¡ ì‹ ê·œì„±ì´ ë†’ìŒ
                novelty = 1.0 / (1.0 + popularity_scores[item_id])
                novelty_scores.append(novelty)
        
        return np.mean(novelty_scores) if novelty_scores else 0.0
    
    def calculate_category_distribution(self, recommendations):
        """
        ì¹´í…Œê³ ë¦¬ ë¶„í¬ ê³„ì‚°
        """
        category_counts = defaultdict(int)
        
        for item_id, _ in recommendations:
            if item_id < len(self.restaurants_df):
                # ê°€ì¥ ë†’ì€ íŠ¹ì„±ê°’ì„ ê°€ì§„ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
                features = self.restaurants_df.iloc[item_id][self.feature_cols].values
                max_feature_idx = np.argmax(features)
                category = self.feature_cols[max_feature_idx]
                category_counts[category] += 1
        
        # ë¶„í¬ì˜ ê· ë“±ì„± ê³„ì‚° (ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜)
        total = sum(category_counts.values())
        if total == 0:
            return 0.0
        
        entropy = 0.0
        for count in category_counts.values():
            if count > 0:
                p = count / total
                entropy -= p * np.log2(p)
        
        # ì •ê·œí™” (ìµœëŒ€ ì—”íŠ¸ë¡œí”¼ë¡œ ë‚˜ëˆ„ê¸°)
        max_entropy = np.log2(len(self.feature_cols))
        return entropy / max_entropy if max_entropy > 0 else 0.0
    
    def evaluate_agent_performance(self, agent, n_users=5, n_recommendations=10):
        """
        ì—ì´ì „íŠ¸ ì „ì²´ ì„±ëŠ¥ í‰ê°€
        """
        print("ğŸ” ì—ì´ì „íŠ¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...")
        
        all_metrics = []
        
        for user_id in range(min(n_users, agent.n_users)):
            # ì‚¬ìš©ìë³„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = np.random.rand(agent.context_dim)
            context /= np.sum(context)
            
            # ì¶”ì²œ ìƒì„±
            recommendations = agent.get_top_k_recommendations(
                user_id, k=n_recommendations, context=context
            )
            
            # í‰ê°€ ìˆ˜í–‰
            metrics = self.evaluate_recommendations(user_id, recommendations)
            all_metrics.append(metrics)
            
            print(f"User {user_id}:")
            print(f"  ë‹¤ì–‘ì„±: {metrics['diversity']:.3f}")
            print(f"  ì»¤ë²„ë¦¬ì§€: {metrics['coverage']:.3f}")
            print(f"  ì‹ ê·œì„±: {metrics['novelty']:.3f}")
            print(f"  ì¹´í…Œê³ ë¦¬ ê· ë“±ì„±: {metrics['category_distribution']:.3f}")
            print(f"  í‰ê·  ì ìˆ˜: {metrics['avg_score']:.3f}")
            print()
        
        # ì „ì²´ í‰ê·  ê³„ì‚°
        avg_metrics = {}
        for key in all_metrics[0].keys():
            if key != 'category_distribution':  # dictëŠ” ì œì™¸
                avg_metrics[key] = np.mean([m[key] for m in all_metrics])
        
        print("ğŸ“Š ì „ì²´ í‰ê·  ì„±ëŠ¥:")
        for key, value in avg_metrics.items():
            print(f"  {key}: {value:.3f}")
        
        return all_metrics, avg_metrics
    
    def plot_evaluation_results(self, save_path='evaluation_results.png'):
        """
        í‰ê°€ ê²°ê³¼ ì‹œê°í™”
        """
        if not self.evaluation_history:
            print("í‰ê°€ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„° ì¤€ë¹„
        metrics_df = []
        for record in self.evaluation_history:
            row = {
                'user_id': record['user_id'],
                'timestamp': record['timestamp'],
                **record['metrics']
            }
            # dict íƒ€ì… ì œì™¸
            row = {k: v for k, v in row.items() if not isinstance(v, dict)}
            metrics_df.append(row)
        
        metrics_df = pd.DataFrame(metrics_df)
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Recommendation System Performance Evaluation', fontsize=16, fontweight='bold')
        
        # 1. ë‹¤ì–‘ì„± ë¶„í¬
        axes[0, 0].hist(metrics_df['diversity'], bins=20, alpha=0.7, color='skyblue')
        axes[0, 0].set_title('Diversity Distribution')
        axes[0, 0].set_xlabel('Diversity Score')
        axes[0, 0].set_ylabel('Frequency')
        
        # 2. ì»¤ë²„ë¦¬ì§€ vs ì‹ ê·œì„±
        axes[0, 1].scatter(metrics_df['coverage'], metrics_df['novelty'], alpha=0.6, color='orange')
        axes[0, 1].set_title('Coverage vs Novelty')
        axes[0, 1].set_xlabel('Coverage')
        axes[0, 1].set_ylabel('Novelty')
        
        # 3. ì‹œê°„ì— ë”°ë¥¸ í‰ê·  ì ìˆ˜
        if len(metrics_df) > 1:
            metrics_df = metrics_df.sort_values('timestamp')
            axes[1, 0].plot(range(len(metrics_df)), metrics_df['avg_score'], marker='o', color='green')
            axes[1, 0].set_title('Average Score Over Time')
            axes[1, 0].set_xlabel('Evaluation Order')
            axes[1, 0].set_ylabel('Average Score')
        
        # 4. ì‚¬ìš©ìë³„ ì„±ëŠ¥ ë¹„êµ
        user_performance = metrics_df.groupby('user_id')[['diversity', 'novelty', 'coverage']].mean()
        user_performance.plot(kind='bar', ax=axes[1, 1])
        axes[1, 1].set_title('Average Performance by User')
        axes[1, 1].set_xlabel('User ID')
        axes[1, 1].set_ylabel('Score')
        axes[1, 1].legend()
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ì €ì¥
        save_dir = os.path.dirname(save_path)
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
        else:
            os.makedirs('.', exist_ok=True)
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close(fig)  # ë©”ëª¨ë¦¬ í•´ì œ
        print(f"ğŸ“Š í‰ê°€ ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: {save_path}")
        
        return fig
    
    def generate_evaluation_report(self, agent, save_path='evaluation_report.txt'):
        """
        í‰ê°€ ë³´ê³ ì„œ ìƒì„±
        """
        print("ğŸ“ í‰ê°€ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
        all_metrics, avg_metrics = self.evaluate_agent_performance(agent)
        
        # ë³´ê³ ì„œ ì‘ì„±
        report = []
        report.append("=" * 60)
        report.append("ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ë³´ê³ ì„œ")
        report.append("=" * 60)
        report.append(f"í‰ê°€ ì¼ì‹œ: {pd.Timestamp.now()}")
        report.append(f"í‰ê°€ ëŒ€ìƒ: {type(agent).__name__}")
        report.append(f"ì‚¬ìš©ì ìˆ˜: {agent.n_users}")
        report.append(f"ì•„ì´í…œ ìˆ˜: {agent.n_items}")
        report.append(f"ì»¨í…ìŠ¤íŠ¸ ì°¨ì›: {agent.context_dim}")
        report.append("")
        
        report.append("ğŸ“Š ì „ì²´ í‰ê·  ì„±ëŠ¥:")
        report.append("-" * 30)
        for key, value in avg_metrics.items():
            report.append(f"{key:20}: {value:.4f}")
        report.append("")
        
        report.append("ğŸ“ˆ ì„±ëŠ¥ í•´ì„:")
        report.append("-" * 30)
        
        # ë‹¤ì–‘ì„± í•´ì„
        diversity_score = avg_metrics['diversity']
        if diversity_score > 0.7:
            report.append("âœ… ë‹¤ì–‘ì„±: ìš°ìˆ˜ - ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì˜ ì•„ì´í…œì„ ì¶”ì²œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif diversity_score > 0.4:
            report.append("âš ï¸ ë‹¤ì–‘ì„±: ë³´í†µ - ì¶”ì²œ ë‹¤ì–‘ì„±ì„ ê°œì„ í•  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.")
        else:
            report.append("âŒ ë‹¤ì–‘ì„±: ë‚®ìŒ - ë¹„ìŠ·í•œ ì•„ì´í…œë“¤ë§Œ ì¶”ì²œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ì‹ ê·œì„± í•´ì„
        novelty_score = avg_metrics['novelty']
        if novelty_score > 0.6:
            report.append("âœ… ì‹ ê·œì„±: ìš°ìˆ˜ - ìƒˆë¡œìš´ ì•„ì´í…œë“¤ì„ ì˜ ë°œêµ´í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif novelty_score > 0.3:
            report.append("âš ï¸ ì‹ ê·œì„±: ë³´í†µ - ì¸ê¸° ì•„ì´í…œê³¼ ì‹ ê·œ ì•„ì´í…œì˜ ê· í˜•ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            report.append("âŒ ì‹ ê·œì„±: ë‚®ìŒ - ì¸ê¸° ì•„ì´í…œì—ë§Œ ì¹˜ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        # ì»¤ë²„ë¦¬ì§€ í•´ì„
        coverage_score = avg_metrics['coverage']
        if coverage_score > 0.5:
            report.append("âœ… ì»¤ë²„ë¦¬ì§€: ìš°ìˆ˜ - ì „ì²´ ì•„ì´í…œì˜ ì ˆë°˜ ì´ìƒì„ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif coverage_score > 0.2:
            report.append("âš ï¸ ì»¤ë²„ë¦¬ì§€: ë³´í†µ - ë” ë§ì€ ì•„ì´í…œì„ ì¶”ì²œì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            report.append("âŒ ì»¤ë²„ë¦¬ì§€: ë‚®ìŒ - ì œí•œëœ ì•„ì´í…œë“¤ë§Œ ì¶”ì²œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        report.append("")
        report.append("ğŸ’¡ ê°œì„  ì œì•ˆ:")
        report.append("-" * 30)
        
        if diversity_score < 0.5:
            report.append("- ë‹¤ì–‘ì„± ê°œì„ : ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì˜ ì•„ì´í…œì„ ê· í˜•ìˆê²Œ ì¶”ì²œ")
        if novelty_score < 0.4:
            report.append("- ì‹ ê·œì„± ê°œì„ : ì¸ê¸°ë„ê°€ ë‚®ì€ ìƒˆë¡œìš´ ì•„ì´í…œë„ ì¶”ì²œì— í¬í•¨")
        if coverage_score < 0.3:
            report.append("- ì»¤ë²„ë¦¬ì§€ ê°œì„ : ë” ë§ì€ ì•„ì´í…œì„ ì¶”ì²œ í›„ë³´ë¡œ ê³ ë ¤")
        
        report.append("")
        report.append("=" * 60)
        
        # íŒŒì¼ ì €ì¥
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print(f"ğŸ“ í‰ê°€ ë³´ê³ ì„œ ì €ì¥: {save_path}")
        
        # í„°ë¯¸ë„ì—ë„ ì¶œë ¥
        print('\n'.join(report))
        
        return '\n'.join(report) 